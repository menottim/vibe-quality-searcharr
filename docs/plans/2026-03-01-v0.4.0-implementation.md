# v0.4.0 Implementation Plan — Prowlarr Integration + Season Pack Intelligence

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Add Prowlarr-aware indexer rate limiting and Sonarr season pack search to the search execution pipeline.

**Architecture:** Two independent features sharing the search execution path. Prowlarr integration adds a new model, client, and service that hooks into the rate limit resolution before each search run. Season Pack adds per-queue config fields and a grouping step in `_search_paginated_records`. Both features are additive — no existing behavior changes when disabled.

**Tech Stack:** Python 3.13, SQLAlchemy (sync), httpx (async), Pydantic schemas, Jinja2 templates, pytest

---

## Task 1: ProwlarrConfig Model

**Files:**
- Create: `src/splintarr/models/prowlarr.py`
- Modify: `src/splintarr/models/__init__.py`
- Test: `tests/unit/test_prowlarr_model.py`

**Step 1: Write the failing test**

```python
"""Tests for ProwlarrConfig model."""
import pytest
from splintarr.models.prowlarr import ProwlarrConfig


class TestProwlarrConfigModel:
    def test_create_prowlarr_config(self, db_session):
        """ProwlarrConfig can be created with required fields."""
        config = ProwlarrConfig(
            user_id=1,
            url="https://prowlarr.example.com",
            encrypted_api_key="encrypted_key_placeholder",
        )
        db_session.add(config)
        db_session.commit()
        db_session.refresh(config)

        assert config.id is not None
        assert config.url == "https://prowlarr.example.com"
        assert config.is_active is True
        assert config.verify_ssl is True
        assert config.sync_interval_minutes == 60

    def test_singleton_per_user(self, db_session):
        """Only one ProwlarrConfig per user_id (unique constraint)."""
        config1 = ProwlarrConfig(user_id=1, url="https://a.com", encrypted_api_key="key1")
        db_session.add(config1)
        db_session.commit()

        config2 = ProwlarrConfig(user_id=1, url="https://b.com", encrypted_api_key="key2")
        db_session.add(config2)
        with pytest.raises(Exception):  # IntegrityError
            db_session.commit()
```

**Step 2: Run test to verify it fails**

Run: `.venv/bin/python -m pytest tests/unit/test_prowlarr_model.py -v --no-cov`
Expected: FAIL — `ModuleNotFoundError: No module named 'splintarr.models.prowlarr'`

**Step 3: Write minimal implementation**

`src/splintarr/models/prowlarr.py`:
```python
"""ProwlarrConfig model for Prowlarr API connection settings."""

from sqlalchemy import Boolean, Column, DateTime, ForeignKey, Integer, String, Text
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func

from splintarr.database import Base


class ProwlarrConfig(Base):
    """Singleton-per-user Prowlarr connection config.

    Stores the Prowlarr URL and encrypted API key. Indexer data is read
    live from the Prowlarr API — no local indexer tables.
    """

    __tablename__ = "prowlarr_configs"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(
        Integer,
        ForeignKey("users.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
        index=True,
    )
    url = Column(String(255), nullable=False)
    encrypted_api_key = Column(Text, nullable=False)
    verify_ssl = Column(Boolean, default=True, nullable=False)
    sync_interval_minutes = Column(Integer, default=60, nullable=False)
    is_active = Column(Boolean, default=True, nullable=False)
    last_sync_at = Column(DateTime, nullable=True)
    created_at = Column(DateTime, server_default=func.now(), nullable=False)
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now(), nullable=False)

    user = relationship("User", back_populates="prowlarr_config")
```

Add to `src/splintarr/models/__init__.py`:
```python
from splintarr.models.prowlarr import ProwlarrConfig  # noqa: F401
```

Add relationship to `src/splintarr/models/user.py`:
```python
prowlarr_config = relationship("ProwlarrConfig", back_populates="user", uselist=False)
```

**Step 4: Run test to verify it passes**

Run: `.venv/bin/python -m pytest tests/unit/test_prowlarr_model.py -v --no-cov`
Expected: PASS

**Step 5: Commit**

```
git add src/splintarr/models/prowlarr.py src/splintarr/models/__init__.py src/splintarr/models/user.py tests/unit/test_prowlarr_model.py
git commit -m "feat: add ProwlarrConfig model (singleton-per-user)"
```

---

## Task 2: ProwlarrClient

**Files:**
- Create: `src/splintarr/services/prowlarr.py`
- Test: `tests/unit/test_prowlarr_client.py`

**Step 1: Write the failing test**

```python
"""Tests for ProwlarrClient API methods."""
import pytest
from unittest.mock import AsyncMock, patch

from splintarr.services.prowlarr import ProwlarrClient


class TestProwlarrClient:
    @pytest.mark.asyncio
    async def test_get_indexers_parses_limits(self):
        """get_indexers extracts QueryLimit/GrabLimit from fields array."""
        raw_indexers = [
            {
                "id": 1,
                "name": "NZBgeek",
                "enable": True,
                "protocol": "usenet",
                "fields": [
                    {"name": "QueryLimit", "value": 100},
                    {"name": "GrabLimit", "value": 50},
                    {"name": "LimitsUnit", "value": 0},  # 0=Day
                ],
                "tags": [1, 2],
                "status": {"disabledTill": None},
            }
        ]
        async with ProwlarrClient(
            url="https://prowlarr.test", api_key="testkey"
        ) as client:
            with patch.object(client, "_request", new_callable=AsyncMock, return_value=raw_indexers):
                indexers = await client.get_indexers()

        assert len(indexers) == 1
        assert indexers[0]["query_limit"] == 100
        assert indexers[0]["grab_limit"] == 50
        assert indexers[0]["limits_unit"] == "day"
        assert indexers[0]["tags"] == [1, 2]

    @pytest.mark.asyncio
    async def test_get_applications(self):
        """get_applications returns parsed app list with tags and URLs."""
        raw_apps = [
            {
                "id": 1,
                "name": "Sonarr",
                "implementation": "Sonarr",
                "tags": [1],
                "fields": [
                    {"name": "BaseUrl", "value": "https://sonarr.test"},
                    {"name": "ApiKey", "value": "sonarr_key"},
                ],
            }
        ]
        async with ProwlarrClient(
            url="https://prowlarr.test", api_key="testkey"
        ) as client:
            with patch.object(client, "_request", new_callable=AsyncMock, return_value=raw_apps):
                apps = await client.get_applications()

        assert len(apps) == 1
        assert apps[0]["base_url"] == "https://sonarr.test"
        assert apps[0]["tags"] == [1]

    @pytest.mark.asyncio
    async def test_get_indexer_stats(self):
        """get_indexer_stats returns per-indexer query/grab counts."""
        raw_stats = {
            "indexers": [
                {
                    "indexerId": 1,
                    "indexerName": "NZBgeek",
                    "numberOfQueries": 42,
                    "numberOfGrabs": 5,
                }
            ]
        }
        async with ProwlarrClient(
            url="https://prowlarr.test", api_key="testkey"
        ) as client:
            with patch.object(client, "_request", new_callable=AsyncMock, return_value=raw_stats):
                stats = await client.get_indexer_stats()

        assert stats[1]["queries"] == 42
        assert stats[1]["grabs"] == 5
```

**Step 2: Run test to verify it fails**

Run: `.venv/bin/python -m pytest tests/unit/test_prowlarr_client.py -v --no-cov`
Expected: FAIL — `ModuleNotFoundError`

**Step 3: Write minimal implementation**

`src/splintarr/services/prowlarr.py`:
```python
"""Prowlarr API client for indexer configuration and rate limit data."""

from datetime import datetime, timedelta

import structlog

from splintarr.services.base_client import (
    ArrAPIError,
    ArrAuthenticationError,
    ArrClientError,
    ArrConnectionError,
    ArrRateLimitError,
    BaseArrClient,
)

logger = structlog.get_logger()


class ProwlarrError(ArrClientError):
    pass

class ProwlarrConnectionError(ArrConnectionError):
    pass

class ProwlarrAuthenticationError(ArrAuthenticationError):
    pass

class ProwlarrAPIError(ArrAPIError):
    pass

class ProwlarrRateLimitError(ArrRateLimitError):
    pass


class ProwlarrClient(BaseArrClient):
    """Client for Prowlarr API v1."""

    service_name = "prowlarr"
    _error_base = ProwlarrError
    _error_connection = ProwlarrConnectionError
    _error_auth = ProwlarrAuthenticationError
    _error_api = ProwlarrAPIError
    _error_rate = ProwlarrRateLimitError

    async def get_indexers(self) -> list[dict]:
        """Fetch indexers with parsed rate limit fields."""
        raw = await self._request("GET", "/api/v1/indexer")
        result = []
        for idx in raw:
            fields = {f["name"]: f.get("value") for f in idx.get("fields", [])}
            limits_unit_raw = fields.get("LimitsUnit", 0)
            limits_unit = "hour" if limits_unit_raw == 1 else "day"
            status = idx.get("status") or {}
            result.append({
                "id": idx["id"],
                "name": idx["name"],
                "enable": idx.get("enable", False),
                "protocol": idx.get("protocol"),
                "query_limit": fields.get("QueryLimit"),
                "grab_limit": fields.get("GrabLimit"),
                "limits_unit": limits_unit,
                "tags": idx.get("tags", []),
                "disabled_till": status.get("disabledTill"),
            })
        return result

    async def get_applications(self) -> list[dict]:
        """Fetch application configs with parsed base URLs and tags."""
        raw = await self._request("GET", "/api/v1/applications")
        result = []
        for app in raw:
            fields = {f["name"]: f.get("value") for f in app.get("fields", [])}
            result.append({
                "id": app["id"],
                "name": app["name"],
                "implementation": app.get("implementation"),
                "base_url": fields.get("BaseUrl", "").rstrip("/"),
                "tags": app.get("tags", []),
            })
        return result

    async def get_indexer_stats(
        self, hours: int = 24
    ) -> dict[int, dict]:
        """Fetch indexer usage stats. Returns dict keyed by indexer_id."""
        end = datetime.utcnow()
        start = end - timedelta(hours=hours)
        raw = await self._request(
            "GET",
            "/api/v1/indexerstats",
            params={
                "startDate": start.isoformat(),
                "endDate": end.isoformat(),
            },
        )
        stats = {}
        for idx in raw.get("indexers", []):
            stats[idx["indexerId"]] = {
                "name": idx.get("indexerName"),
                "queries": idx.get("numberOfQueries", 0),
                "grabs": idx.get("numberOfGrabs", 0),
                "failed_queries": idx.get("numberOfFailedQueries", 0),
            }
        return stats

    async def get_indexer_status(self) -> list[dict]:
        """Fetch circuit-breaker status for indexers."""
        raw = await self._request("GET", "/api/v1/indexerstatus")
        return [
            {
                "indexer_id": s.get("indexerId"),
                "disabled_till": s.get("disabledTill"),
            }
            for s in raw
        ]
```

**Step 4: Run test to verify it passes**

Run: `.venv/bin/python -m pytest tests/unit/test_prowlarr_client.py -v --no-cov`
Expected: PASS

**Step 5: Commit**

```
git add src/splintarr/services/prowlarr.py tests/unit/test_prowlarr_client.py
git commit -m "feat: add ProwlarrClient with indexer/app/stats API methods"
```

---

## Task 3: IndexerRateLimitService

**Files:**
- Create: `src/splintarr/services/indexer_rate_limit.py`
- Test: `tests/unit/test_indexer_rate_limit.py`

**Step 1: Write the failing test**

```python
"""Tests for IndexerRateLimitService."""
import pytest
from unittest.mock import AsyncMock, MagicMock, patch

from splintarr.services.indexer_rate_limit import IndexerRateLimitService


class TestIndexerRateLimitService:
    @pytest.mark.asyncio
    async def test_no_prowlarr_config_returns_instance_rate(self):
        """Without Prowlarr config, returns the instance's own rate limit."""
        db = MagicMock()
        db.query.return_value.filter.return_value.first.return_value = None  # no config

        service = IndexerRateLimitService(db)
        result = await service.get_effective_limit(instance_id=1, user_id=1, instance_rate=5.0)

        assert result == {"rate_per_second": 5.0, "max_items": None, "source": "instance"}

    @pytest.mark.asyncio
    async def test_prowlarr_with_limits_caps_items(self):
        """With Prowlarr indexer limits, returns remaining budget as max_items."""
        db = MagicMock()
        prowlarr_config = MagicMock()
        prowlarr_config.url = "https://prowlarr.test"
        prowlarr_config.encrypted_api_key = "encrypted"
        prowlarr_config.verify_ssl = True
        prowlarr_config.is_active = True
        db.query.return_value.filter.return_value.first.return_value = prowlarr_config

        mock_client = AsyncMock()
        mock_client.get_indexers.return_value = [
            {"id": 1, "name": "NZBgeek", "enable": True, "query_limit": 100,
             "grab_limit": None, "limits_unit": "day", "tags": [],
             "disabled_till": None},
        ]
        mock_client.get_applications.return_value = [
            {"id": 1, "name": "Sonarr", "implementation": "Sonarr",
             "base_url": "https://sonarr.test", "tags": []},
        ]
        mock_client.get_indexer_stats.return_value = {
            1: {"name": "NZBgeek", "queries": 60, "grabs": 3, "failed_queries": 0},
        }

        service = IndexerRateLimitService(db)
        with patch("splintarr.services.indexer_rate_limit.decrypt_api_key", return_value="a" * 32):
            with patch("splintarr.services.indexer_rate_limit.ProwlarrClient") as MockClient:
                MockClient.return_value.__aenter__ = AsyncMock(return_value=mock_client)
                MockClient.return_value.__aexit__ = AsyncMock(return_value=False)
                result = await service.get_effective_limit(
                    instance_id=1, user_id=1,
                    instance_rate=5.0, instance_url="https://sonarr.test"
                )

        assert result["source"] == "prowlarr"
        assert result["max_items"] == 40  # 100 limit - 60 used

    @pytest.mark.asyncio
    async def test_prowlarr_unreachable_falls_back(self):
        """If Prowlarr API fails, falls back to instance rate."""
        db = MagicMock()
        prowlarr_config = MagicMock()
        prowlarr_config.url = "https://prowlarr.test"
        prowlarr_config.encrypted_api_key = "encrypted"
        prowlarr_config.verify_ssl = True
        prowlarr_config.is_active = True
        db.query.return_value.filter.return_value.first.return_value = prowlarr_config

        service = IndexerRateLimitService(db)
        with patch("splintarr.services.indexer_rate_limit.decrypt_api_key", return_value="a" * 32):
            with patch("splintarr.services.indexer_rate_limit.ProwlarrClient") as MockClient:
                MockClient.return_value.__aenter__ = AsyncMock(side_effect=Exception("connection refused"))
                result = await service.get_effective_limit(
                    instance_id=1, user_id=1, instance_rate=5.0
                )

        assert result["source"] == "instance"
        assert result["rate_per_second"] == 5.0
```

**Step 2: Run test to verify it fails**

Run: `.venv/bin/python -m pytest tests/unit/test_indexer_rate_limit.py -v --no-cov`
Expected: FAIL — `ModuleNotFoundError`

**Step 3: Write minimal implementation**

`src/splintarr/services/indexer_rate_limit.py`:
```python
"""Resolve effective rate limits using Prowlarr indexer data."""

from urllib.parse import urlparse

import structlog
from sqlalchemy.orm import Session

from splintarr.core.security import decrypt_api_key
from splintarr.models.prowlarr import ProwlarrConfig
from splintarr.services.prowlarr import ProwlarrClient

logger = structlog.get_logger()


class IndexerRateLimitService:
    """Resolves per-instance rate limits from Prowlarr indexer configs."""

    def __init__(self, db: Session):
        self.db = db

    async def get_effective_limit(
        self,
        instance_id: int,
        user_id: int,
        instance_rate: float,
        instance_url: str | None = None,
    ) -> dict:
        """Return effective rate limit for an instance.

        Returns dict with keys: rate_per_second, max_items (int|None), source ("prowlarr"|"instance").
        """
        fallback = {"rate_per_second": instance_rate, "max_items": None, "source": "instance"}

        config = (
            self.db.query(ProwlarrConfig)
            .filter(ProwlarrConfig.user_id == user_id, ProwlarrConfig.is_active.is_(True))
            .first()
        )
        if not config:
            return fallback

        try:
            api_key = decrypt_api_key(config.encrypted_api_key)
            async with ProwlarrClient(
                url=config.url, api_key=api_key, verify_ssl=config.verify_ssl
            ) as client:
                indexers = await client.get_indexers()
                apps = await client.get_applications()
                stats = await client.get_indexer_stats(
                    hours=24  # day window; adjusted to 1 for hourly limits below
                )

            # Match instance to Prowlarr application by URL
            app = self._match_application(apps, instance_url)
            if not app:
                logger.debug(
                    "prowlarr_no_matching_app",
                    instance_id=instance_id,
                    instance_url=instance_url,
                )
                return fallback

            # Find connected indexers via tag intersection
            connected = self._get_connected_indexers(indexers, app)
            if not connected:
                return fallback

            # Calculate minimum remaining budget
            min_remaining = None
            for idx in connected:
                query_limit = idx.get("query_limit")
                if query_limit is None:
                    continue  # no limit configured on this indexer

                # Get stats for the correct time window
                idx_stats = stats.get(idx["id"], {})
                used = idx_stats.get("queries", 0)
                remaining = max(0, query_limit - used)

                if min_remaining is None or remaining < min_remaining:
                    min_remaining = remaining

            if min_remaining is not None:
                logger.info(
                    "prowlarr_rate_limit_resolved",
                    instance_id=instance_id,
                    remaining_budget=min_remaining,
                    connected_indexers=len(connected),
                )
                return {
                    "rate_per_second": instance_rate,
                    "max_items": min_remaining,
                    "source": "prowlarr",
                }

            return fallback

        except Exception as e:
            logger.warning(
                "prowlarr_rate_limit_failed",
                instance_id=instance_id,
                error=str(e),
            )
            return fallback

    def _match_application(
        self, apps: list[dict], instance_url: str | None
    ) -> dict | None:
        """Match a Sonarr/Radarr instance URL to a Prowlarr application."""
        if not instance_url:
            return None
        instance_host = urlparse(instance_url.rstrip("/")).netloc.lower()
        for app in apps:
            app_host = urlparse(app.get("base_url", "").rstrip("/")).netloc.lower()
            if app_host and app_host == instance_host:
                return app
        return None

    def _get_connected_indexers(
        self, indexers: list[dict], app: dict
    ) -> list[dict]:
        """Filter indexers connected to an application via tag intersection."""
        app_tags = set(app.get("tags", []))
        connected = []
        for idx in indexers:
            if not idx.get("enable", False):
                continue
            if idx.get("disabled_till"):
                continue
            idx_tags = set(idx.get("tags", []))
            # No tags on app = all indexers; otherwise require intersection
            if not app_tags or app_tags & idx_tags:
                connected.append(idx)
        return connected
```

**Step 4: Run test to verify it passes**

Run: `.venv/bin/python -m pytest tests/unit/test_indexer_rate_limit.py -v --no-cov`
Expected: PASS

**Step 5: Commit**

```
git add src/splintarr/services/indexer_rate_limit.py tests/unit/test_indexer_rate_limit.py
git commit -m "feat: add IndexerRateLimitService with Prowlarr-aware rate resolution"
```

---

## Task 4: Season Pack — Model + Schema + Client

**Files:**
- Modify: `src/splintarr/models/search_queue.py`
- Modify: `src/splintarr/schemas/search.py`
- Modify: `src/splintarr/services/sonarr.py`
- Test: `tests/unit/test_season_pack.py`

**Step 1: Write the failing test**

```python
"""Tests for season pack model fields, schema, and Sonarr client method."""
import pytest
from unittest.mock import AsyncMock, patch

from splintarr.models.search_queue import SearchQueue
from splintarr.schemas.search import SearchQueueCreate
from splintarr.services.sonarr import SonarrClient


class TestSeasonPackModel:
    def test_season_pack_defaults(self, db_session):
        """SearchQueue has season pack fields with correct defaults."""
        queue = SearchQueue(
            instance_id=1, name="Test", strategy="missing",
            is_recurring=False, status="pending",
        )
        db_session.add(queue)
        db_session.commit()
        db_session.refresh(queue)

        assert queue.season_pack_enabled is False
        assert queue.season_pack_threshold == 3


class TestSeasonPackSchema:
    def test_create_with_season_pack(self):
        """SearchQueueCreate accepts season pack fields."""
        data = SearchQueueCreate(
            instance_id=1, name="Test Queue", strategy="missing",
            season_pack_enabled=True, season_pack_threshold=5,
        )
        assert data.season_pack_enabled is True
        assert data.season_pack_threshold == 5

    def test_threshold_validation(self):
        """Threshold must be between 2 and 50."""
        with pytest.raises(Exception):
            SearchQueueCreate(
                instance_id=1, name="Test Queue", strategy="missing",
                season_pack_enabled=True, season_pack_threshold=1,
            )


class TestSonarrSeasonSearch:
    @pytest.mark.asyncio
    async def test_season_search_command(self):
        """season_search posts SeasonSearch command to Sonarr API."""
        async with SonarrClient(url="https://sonarr.test", api_key="test") as client:
            with patch.object(client, "_request", new_callable=AsyncMock, return_value={"id": 99}) as mock:
                result = await client.season_search(series_id=42, season_number=3)

        mock.assert_called_once_with(
            "POST", "/api/v3/command",
            json={"name": "SeasonSearch", "seriesId": 42, "seasonNumber": 3},
        )
        assert result == {"id": 99}
```

**Step 2: Run test to verify it fails**

Run: `.venv/bin/python -m pytest tests/unit/test_season_pack.py -v --no-cov`
Expected: FAIL — `season_pack_enabled` not defined

**Step 3: Write minimal implementation**

Add to `src/splintarr/models/search_queue.py` (after `max_items_per_run` column):
```python
    season_pack_enabled = Column(
        Boolean, default=False, nullable=False,
        comment="Enable season pack search for Sonarr instances",
    )
    season_pack_threshold = Column(
        Integer, default=3, nullable=False,
        comment="Minimum missing episodes per season to trigger season pack search (2-50)",
    )
```

Add to `src/splintarr/schemas/search.py` `SearchQueueCreate` class:
```python
    season_pack_enabled: bool = Field(default=False)
    season_pack_threshold: int = Field(default=3, ge=2, le=50)
```

Add same fields to `SearchQueueUpdate` and `SearchQueueResponse`.

Add to `src/splintarr/services/sonarr.py`:
```python
    async def season_search(self, series_id: int, season_number: int) -> dict:
        """Issue a SeasonSearch command for a specific series + season."""
        logger.info(
            "sonarr_season_search_triggered",
            series_id=series_id,
            season_number=season_number,
        )
        return await self._request(
            "POST",
            "/api/v3/command",
            json={"name": "SeasonSearch", "seriesId": series_id, "seasonNumber": season_number},
        )
```

**Step 4: Run test to verify it passes**

Run: `.venv/bin/python -m pytest tests/unit/test_season_pack.py -v --no-cov`
Expected: PASS

**Step 5: Commit**

```
git add src/splintarr/models/search_queue.py src/splintarr/schemas/search.py src/splintarr/services/sonarr.py tests/unit/test_season_pack.py
git commit -m "feat: add season pack model fields, schema validation, and Sonarr season_search"
```

---

## Task 5: Season Pack — Search Execution Logic

**Files:**
- Modify: `src/splintarr/services/search_queue.py`
- Test: `tests/unit/test_season_pack_execution.py`

**Step 1: Write the failing test**

```python
"""Tests for season pack grouping and execution in search queue."""
import pytest
from splintarr.services.search_queue import _group_by_season


class TestSeasonPackGrouping:
    def test_groups_episodes_by_series_and_season(self):
        """Episodes are grouped by (series_id, season_number)."""
        records = [
            {"id": 1, "seriesId": 10, "seasonNumber": 1},
            {"id": 2, "seriesId": 10, "seasonNumber": 1},
            {"id": 3, "seriesId": 10, "seasonNumber": 1},
            {"id": 4, "seriesId": 10, "seasonNumber": 2},
            {"id": 5, "seriesId": 20, "seasonNumber": 1},
        ]
        groups = _group_by_season(records)
        assert len(groups[(10, 1)]) == 3
        assert len(groups[(10, 2)]) == 1
        assert len(groups[(20, 1)]) == 1

    def test_splits_packs_from_singles(self):
        """Groups at or above threshold become packs, rest stay as singles."""
        records = [
            {"id": 1, "seriesId": 10, "seasonNumber": 1},
            {"id": 2, "seriesId": 10, "seasonNumber": 1},
            {"id": 3, "seriesId": 10, "seasonNumber": 1},
            {"id": 4, "seriesId": 10, "seasonNumber": 2},
        ]
        groups = _group_by_season(records)
        threshold = 3
        packs = {k: v for k, v in groups.items() if len(v) >= threshold}
        singles = [r for k, v in groups.items() if len(v) < threshold for r in v]

        assert (10, 1) in packs
        assert len(singles) == 1
        assert singles[0]["id"] == 4
```

**Step 2: Run test to verify it fails**

Run: `.venv/bin/python -m pytest tests/unit/test_season_pack_execution.py -v --no-cov`
Expected: FAIL — `cannot import name '_group_by_season'`

**Step 3: Write minimal implementation**

Add to `src/splintarr/services/search_queue.py`:

```python
from collections import defaultdict

def _group_by_season(records: list[dict]) -> dict[tuple[int, int], list[dict]]:
    """Group Sonarr records by (seriesId, seasonNumber) for season pack detection."""
    groups: dict[tuple[int, int], list[dict]] = defaultdict(list)
    for record in records:
        series_id = record.get("seriesId")
        season = record.get("seasonNumber")
        if series_id is not None and season is not None:
            groups[(series_id, season)].append(record)
    return dict(groups)
```

Then integrate into `_search_paginated_records()` — after step 7 (truncate) and before step 8 (search loop):

```python
# Step 7.5: Season pack grouping (Sonarr only)
season_packs = {}
single_items = scored_items
if is_sonarr and getattr(queue, "season_pack_enabled", False):
    threshold = getattr(queue, "season_pack_threshold", 3) or 3
    groups = _group_by_season([item[0] for item in scored_items])
    pack_ids = set()
    for (series_id, season_num), episodes in groups.items():
        if len(episodes) >= threshold:
            season_packs[(series_id, season_num)] = episodes
            pack_ids.update(ep["id"] for ep in episodes)
    single_items = [(r, s, reason) for r, s, reason in scored_items if r["id"] not in pack_ids]

# Step 8a: Execute season pack searches
for (series_id, season_num), episodes in season_packs.items():
    command = await client.season_search(series_id, season_num)
    searches_triggered += 1
    for ep in episodes:
        ext_id = ep["id"]
        lib_item = library_items.get(str(ext_id))
        if lib_item:
            lib_item.record_search()
    logger.info(
        "season_pack_search_triggered",
        instance_id=instance.id,
        series_id=series_id,
        season_number=season_num,
        episode_count=len(episodes),
    )
```

**Step 4: Run test to verify it passes**

Run: `.venv/bin/python -m pytest tests/unit/test_season_pack_execution.py -v --no-cov`
Expected: PASS

**Step 5: Commit**

```
git add src/splintarr/services/search_queue.py tests/unit/test_season_pack_execution.py
git commit -m "feat: season pack grouping and execution in search queue"
```

---

## Task 6: Prowlarr Integration into Search Execution

**Files:**
- Modify: `src/splintarr/services/search_queue.py`
- Test: `tests/unit/test_prowlarr_integration.py`

**Step 1: Write the failing test**

```python
"""Test Prowlarr rate limit integration in search queue execution."""
import pytest
from unittest.mock import AsyncMock, MagicMock, patch


class TestProwlarrSearchIntegration:
    @pytest.mark.asyncio
    async def test_prowlarr_caps_max_items(self):
        """When Prowlarr returns a budget, max_items is capped."""
        from splintarr.services.search_queue import SearchQueueManager

        mock_rate_service = AsyncMock()
        mock_rate_service.get_effective_limit.return_value = {
            "rate_per_second": 5.0,
            "max_items": 10,
            "source": "prowlarr",
        }

        # Verify that the service would cap items
        result = await mock_rate_service.get_effective_limit(
            instance_id=1, user_id=1, instance_rate=5.0, instance_url="https://sonarr.test"
        )
        assert result["max_items"] == 10
        assert result["source"] == "prowlarr"
```

**Step 2-5: Implement, test, commit**

In `SearchQueueManager.execute_queue()`, before calling `_search_paginated_records`, add:

```python
# Resolve effective rate limit from Prowlarr (if configured)
from splintarr.services.indexer_rate_limit import IndexerRateLimitService
rate_service = IndexerRateLimitService(db)
rate_result = await rate_service.get_effective_limit(
    instance_id=instance.id,
    user_id=queue_user_id,
    instance_rate=instance.rate_limit_per_second or 5.0,
    instance_url=instance.url,
)
if rate_result["max_items"] is not None:
    effective_max = min(queue.max_items_per_run or 50, rate_result["max_items"])
    logger.info(
        "search_queue_rate_limit_applied",
        queue_id=queue_id,
        instance_id=instance.id,
        prowlarr_budget=rate_result["max_items"],
        queue_max=queue.max_items_per_run,
        effective_max=effective_max,
    )
```

Pass `effective_max` into `_search_paginated_records` to override `max_items_per_run`.

```
git commit -m "feat: integrate Prowlarr rate limit into search queue execution"
```

---

## Task 7: Prowlarr API Routes + Settings UI

**Files:**
- Create: `src/splintarr/api/prowlarr.py`
- Modify: `src/splintarr/templates/dashboard/settings.html`
- Modify: `src/splintarr/main.py` (register router)

**Step 1-5:** Add API routes following the notification pattern (get config, save config, test connection, delete config). Add a `<details>` section to settings.html with URL, API key, test button, sync interval. Register the router in main.py.

```
git commit -m "feat: Prowlarr config API routes and Settings UI section"
```

---

## Task 8: Season Pack UI + Queue Modal Updates

**Files:**
- Modify: `src/splintarr/templates/dashboard/search_queues.html`
- Modify: `src/splintarr/templates/dashboard/search_queue_detail.html`
- Modify: `src/splintarr/api/search_queue.py`

**Step 1-5:** Add season pack toggle and threshold input to the Create Queue modal (only visible when instance is Sonarr). Update `getFormData()`, `cloneQueue()`, and presets JS. Update queue detail search log to show "Season Pack" action type. Wire the new fields through the create/update API handlers.

```
git commit -m "feat: season pack UI in queue modal and search log"
```

---

## Task 9: Dashboard Indexer Health Widget

**Files:**
- Modify: `src/splintarr/api/dashboard.py`
- Modify: `src/splintarr/templates/dashboard/index.html`

**Step 1-5:** Add `/api/dashboard/indexer-health` endpoint that reads from Prowlarr (if configured). Return per-indexer name, status, queries used/limit. Add a table widget to the dashboard below existing stats. Only shown when Prowlarr is configured.

```
git commit -m "feat: dashboard indexer health widget from Prowlarr stats"
```

---

## Task 10: Lint, Test, Final Verification

**Step 1:** Run full lint: `.venv/bin/ruff check src/ --fix && .venv/bin/ruff format src/`
**Step 2:** Run full test suite: `.venv/bin/python -m pytest tests/unit/ tests/security/ --no-cov -q`
**Step 3:** Verify zero new failures beyond pre-existing baseline (80 failed, 663 passed)
**Step 4:** Final commit if any lint fixes needed

```
git commit -m "chore: lint and format for v0.4.0"
```
